import cv2
import torch
import supervision as sv
from ultralytics import YOLO
import pytesseract
import numpy as np
from time import time
import os

# 1. TESSERACT CONFIGURATION - SET THIS CORRECTLY
TESSERACT_PATH = r'C:\Users\Kumar Ayush\OCR\tesseract.exe'  # Typical Windows path
if os.path.exists(TESSERACT_PATH):
    pytesseract.pytesseract.tesseract_cmd = TESSERACT_PATH
else:
    print(f"Warning: Tesseract not found at {TESSERACT_PATH}")
    print("Trying system PATH...")

# Configuration
FRAME_SKIP = 2
MIN_CONFIDENCE = 0.3
OCR_RESIZE = 320
DISPLAY_FPS = True

# Initialize model
device = 'cuda' if torch.cuda.is_available() else 'cpu'
original_load = torch.load
torch.load = lambda *args, **kwargs: original_load(*args, **{**kwargs, 'weights_only': False})
model = YOLO('yolov10s-doclaynet.pt')  # Same weights that worked with images

# Initialize camera
cap = cv2.VideoCapture(0)
cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)

# Initialize annotator
box_annotator = sv.BoxAnnotator()

# Performance tracking
frame_count = 0
start_time = time()

def safe_ocr(image):
    """Handle OCR with proper error handling"""
    try:
        # Preprocess
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        gray = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]
        
        # OCR
        text = pytesseract.image_to_string(gray, config='--psm 6 --oem 3')
        return ' '.join(text.strip().split())
    except Exception as e:
        print(f"OCR Error: {str(e)}")
        return None

while True:
    ret, frame = cap.read()
    if not ret:
        break
    
    frame_count += 1
    
    # Skip frames processing
    if frame_count % FRAME_SKIP != 0 and frame_count > 1:
        if 'annotated_frame' in locals():
            cv2.imshow("Live Detection", annotated_frame)
            if cv2.waitKey(1) == ord('q'):
                break
        continue
    
    # Process frame
    results = model(frame, imgsz=640, conf=0.2, iou=0.5, device=device)[0]
    detections = sv.Detections.from_ultralytics(results)
    
    # Filter detections
    high_conf_mask = detections.confidence > MIN_CONFIDENCE
    text_detections = sv.Detections(
        xyxy=detections.xyxy[high_conf_mask],
        confidence=detections.confidence[high_conf_mask],
        class_id=detections.class_id[high_conf_mask]
    )
    
    # Draw boxes
    annotated_frame = frame.copy()
    annotated_frame = box_annotator.annotate(annotated_frame, text_detections)
    
    # Process OCR for each detection
    for i, (xyxy, confidence, class_id) in enumerate(zip(text_detections.xyxy, 
                                                       text_detections.confidence, 
                                                       text_detections.class_id)):
        x1, y1, x2, y2 = map(int, xyxy)
        roi = frame[y1:y2, x1:x2]
        
        if roi.size == 0:
            continue
            
        # OCR Processing
        text = safe_ocr(roi)
        if text:
            # Prepare label
            label = f"{text[:25]}..." if len(text) > 25 else text
            
            # Calculate text position
            text_y = y1 - 10 if y1 - 10 > 10 else y2 + 20
            
            # Draw background for better visibility
            (text_width, text_height), _ = cv2.getTextSize(
                label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)
            cv2.rectangle(annotated_frame, 
                         (x1, text_y - text_height - 5),
                         (x1 + text_width, text_y + 5),
                         (0, 0, 0), -1)
            
            # Draw text
            cv2.putText(annotated_frame, label, (x1, text_y),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 1)
    
    # Show FPS if enabled
    if DISPLAY_FPS:
        fps = frame_count / (time() - start_time)
        cv2.putText(annotated_frame, f"FPS: {fps:.1f}", (10, 30),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
    
    # Display result
    cv2.imshow("Live Detection", annotated_frame)
    if cv2.waitKey(1) == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()
